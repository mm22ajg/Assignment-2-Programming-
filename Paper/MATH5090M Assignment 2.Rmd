---
title: "Evaluating the BOP2 design"
author: "Adam Gough (201612804)"
date: '2023-03-07'
output:
  html_document: default
  pdf_document: default
---

## Introduction

The RESERVE clinical trial studies the efficacy of a particular treatment on patients with relapsed/refractory multiple myeloma (RRMM), a type of bone marrow cancer. RESERVE is a type II clinical trial meaning we are investigating whether or not the patients respond to our treatment. This is important as patients with RRMM may have been unresponsive to treatment before. For safety, we want to be able to stop the trial early if it is clear the treatment is not working. To do this, we will implement the BOP2 (Bayesian optimal phase II) clinical trial design. This report aims to apply the BOP2 design in this scenario, and then evaluate how the design changes when we are better informed prior to the clinical trial.

## The BOP2 design

We will begin with a description of the Bayesian optimal phase II (BOP2) design. Consider the following trial structure:

1.  Stage 1: Recruit $n_1$ patients and monitor their response to treatment.

2.  Based on the data obtained from stage 1, determine whether to continue the trial.

3.  Stage 2: Recruit further $\tilde{n}_2$ patients and monitor their response to treatment.

4.  Based on the full set of data containing $n_2=n_1+\tilde{n}_2$ patients, determine whether to continue to a phase III trial where we would compare the treatment to the current standard.

At each stage, we have a fixed number of patients, each with the same probability of responding to treatment, labelled $\theta$. Also, patient outcomes are independent of each other. Therefore, by the end of stage $i$, the number of patients who have responded to treatment $y_i$ is Binomailly distributed, $$y_i\mid\theta\sim Bin(n_i,\theta)$$

Taking a Bayesian approach, we can attain the posterior distribution for $\theta$ by using the conjugate prior distribution $\theta\sim Beta(a,b)$ and applying Bayes' theorem. We find,$$\theta\mid y_i\sim Beta(a+y_i,b+(n_i-y_i))$$

Now consider the posterior probability of futility, i.e., the probability the patients are not responding to the treatment given the data. In mathematical terms, this can be expressed as $Pr(\theta<0.5\mid y_i)$. To decide whether to continue the trial at each stage, we can assess whether this probability is above a threshold value. The BOP2 design specifies that the threshold at each stage is given by,$$C(n_i)=1-\lambda\left(\frac{n_i}{n_2}\right)^\gamma$$

Here, $\lambda$ and $\gamma$ are called the stopping rule parameters. We restrict ourselves to $0\le\lambda\le1$ and $\gamma>0$. This ensures that $C(n_2)<C(n_1)$, indicating the threshold is more demanding at the end of stage 2, and it is more challenging to progress.

Contemplate a hypothesis test for $\theta$ where $\theta_0$ and $\theta_1$ denote the null and alternative hypotheses, respectively. Then we can define the type I error rate as the probability of continuing the trial at the end of stage 2 under the null hypothesis, and the type II error rate as the probability of stopping the trial at either stage under the alternative hypothesis.

We can now optimise the trial design by finding the stopping rule and sample size parameters which minimise the expected sample size under the null hypothesis, subject to constraints on the type I error rate under the null hypothesis and the type II error rate under the alternative hypothesis.

## Application

Now we can implement the BOP2 clinical trial design in R. Here the null hypothesis is given by $\theta_0=0.5$ and the alternative hypothesis is given by $\theta_1=0.7$. We want to minimise the expected sample size subject to the type I error rate being at most $0.05$ and the type II error rate being at most $0.2$. For the prior distribution we will begin by using $a=0.5$ and $b=0.5$. First, we need to know how to calculate the expected sample sizes and the error rates. Since the sample size $N$ can only take two values, $n_1$ and $n_2$, the expected sample size is given by $$E[N]=n_1Pr(N=n_1)+n_2Pr(N=n_2)$$Since the number of responses has a binomial distribution, we can use the law of total probability to sum over all possible number of responses and write $Pr(N=n_1)$ as $$Pr(N=n_1)=\sum_{y_1=0}^{n_1}I\left[\int_{0}^{0.5}p(\theta\mid y_1)\, d\theta>C_1\right]p(y_1)$$Where $I$ is the indicator function. To find the distribution of $p(y_1)$, we can use the law of total probability again (although this time the continuous case) to obtain$$p(y_1)=\int_{0}^{1}p(y_1\mid \theta)p(\theta)\,d\theta=\binom{n}{k}\frac{B(y_1+a,n_1-y_1+b)}{B(a,b)}$$Where $p(y_1\mid\theta)$ is the likelihood function and $p(\theta)$ is the prior density. Note that $Pr(N=n_2)$ is equivalent to not stopping at stage 1, therefore $$Pr(N=n_2)=\sum_{y_1=0}^{n_1}I\left[\int_{0}^{0.5}p(\theta\mid y_1)\, d\theta<C_1\right]p(y_1)$$We are now ready to program this in RStudio.

```{r}
prob_y <- function(y, n, a, b) {
  # Calculate the probability of observing y responses in n trials
  # under a Beta-binomial model with Beta(a, b) prior.
  
  choose(n, y) * beta(y + a, n - y + b) / beta(a, b)
}

expected_sample_size <- function(lambda, gamma, n1, n2, a, b) {
  
  # Calculate the expected sample size of a BOP2 design defined by its 
  # decision rule parameters (lambda, gamma), sample size parameters 
  # (n1, n2), and prior distribution parameters (a, b)
  
  # Threshold to determine progression.
  C1 <- 1 - lambda * (n1 / n2)^gamma
  
  # Vector of possible stage 1 outcomes.
  y_1s <- 0:n1
  
  # Vector of corresponding progression decisions.
  stops <- pbeta(0.5, y_1s + a, n1 - y_1s + b) > C1
  
  # Calculate the probability of each outcome.
  y_1_probs <- prob_y(y_1s, n1, a, b)
  
  return(sum(n1 * stops * y_1_probs + n2 * (!stops) * y_1_probs))
}
```

We can then use a unit test to check the function `prob_y` and ensure that all the probabilities sum to 1.

```{r}
test_prob_y <- function(a, b) {
  # Check that the probabilities sum to 1.
  n <- 30
  s <- sum(prob_y(0:n, n, a, b))
  return(all.equal(s, 1))
}

test_prob_y(a = 0.5, b = 0.5)
```

The test outputs `TRUE` therefore the function is working correctly.

Now we need to calculate the error rates. We have previously stated that the type I error rate is the probability of continuing the trial at the end of stage 2 under the null hypothesis. Therefore it is given by$$Pr(Type\,I\,error)=\sum_{y_1=0}^{n_1}\sum_{y_2=0}^{n_2-n_1}I[Pr(\theta<0.5\mid y_1)<C_1\cap Pr(\theta<0.5\mid y_2)<C_2]p(y_1\mid\theta=0.5)p(y_2\mid\theta=0.5)$$Similarly the type II error rate is the probability of stopping the trial at either stage under the alternative hypothesis. Therefore$$Pr(Type\,II\,error)=\sum_{y_1=0}^{n_1}\sum_{y_2=0}^{n_2-n_1}I[Pr(\theta<0.5\mid y_1)>C_1\cup Pr(\theta<0.5\mid y_2)>C_2]p(y_1\mid\theta=0.7)p(y_2\mid\theta=0.7)$$Now we can use RStudio to evaluate these probabilities.

```{r echo=TRUE}
prob_y1_and_y2 <- function(y_1, y_2, n1, n2, theta) {
  
  # Calculate the probability of observing y_1 and y_2 given theta.
  dbinom(y_1, n1, theta)*dbinom(y_2, n2 - n1, theta)
}

error_rates <- function(lambda, gamma, n1, n2, a, b) {
  
  # Calculate the type I and II error rates of a BOP2 design defined 
  # by its decision rule parameters (lambda, gamma), sample size 
  # parameters (n1, n2), and prior distribution parameters (a, b).
  
  # Thresholds to determine progression.
  C1 <- 1 - lambda * (n1 / n2)^gamma
  C2 <- 1 - lambda * (n2 / n2)^gamma
  
  # Matrix of possible successes in stage 1 and 2.
  ys <- expand.grid(y_1 = 0:n1, y_2 = 0:(n2 - n1))
  
  # Vectors of corresponding progression decisions at stage 1 and 2.
  go_1 <- pbeta(0.5, ys$y_1 + a, n1 - ys$y_1 + b) < C1
  go_2 <- pbeta(0.5, ys$y_1 + ys$y_2 + a, n2 - ys$y_1 - ys$y_2 + b) < C2
  
  # Vectors of overall progression decisions.
  go_tI <- go_1 & go_2
  go_tII <- !go_1 | !go_2
  
  # Calculate the probability of each outcome.
  probs_tI <- prob_y1_and_y2(ys$y_1, ys$y_2, n1, n2, 0.5)
  probs_tII <- prob_y1_and_y2(ys$y_1, ys$y_2, n1, n2, 0.7)
  
  # Calculate the type I and type II error rates.
  type_I <- sum(go_tI*probs_tI)
  type_II <- sum(go_tII*probs_tII)
  
  return(c(type_I,type_II))
}
```

Notice that these functions also depend on the prior distribution parameters $a$ and $b$. This will be useful when we change how informative the prior distribution is. Now we can create a function which will use a grid search to find the optimal parameters $\lambda$, $\gamma$, $n_1$, and $n_2$.

```{r echo=TRUE}
BOP2optim <- function(a, b){
  
  # Minimise the expected sample size of a BOP2 design subject to the
  # type I error rate being at most 0.05 and the type II error rate 
  # being at most 0.2 using a grid search.
  
  # Create a grid of possible parameter values.
  grid <- expand.grid(lambda = seq(0,1,0.05), gamma = seq(0.05,2,0.05), n1 = seq(4, 20, 4), n2 = seq(5, 80, 5))
  grid <- grid[grid$n1<=grid$n2,]
  
  # Initialise vectors.
  res <- c(max(grid[,4]),0,0)
  
  # Search over the grid for the minimum expected sample size and record
  # the corresponding parameters.
  for(i in 1:nrow(grid)){
    exp_s_s <- expected_sample_size(grid[i,1],grid[i,2],grid[i,3],grid[i,4], a = a, b = b)
    err_rts <- error_rates(grid[i,1],grid[i,2],grid[i,3],grid[i,4], a = a, b = b)
    if(exp_s_s < res[1] & err_rts[1] <= 0.05 & err_rts[2] <= 0.2){
      res <- c(exp_s_s,err_rts[1],err_rts[2])
      par <- grid[i,]
    }
  }
  
  # Return the minimised expected sample size, error rates and 
  # corresponding parameters.
  return(t(c(par, res)))
}

# Optimise the BOP2 design when a = 0.5 and b = 0.5, and record the time
# elapsed.
ptm <- proc.time()
BOP2optim(a = 0.5, b = 0.5)
proc.time() - ptm
```

The minimum expected sample size found by the algorithm is 27.657. This is achieved when $\lambda=0.95$, $\gamma=0.9$, $n_1=8$, and $n_2=40$. These parameters result in a type I error rate of 0.0399 and a type II error rate of 0.196, which both satisfy the constraints. Calculating the threshold values we get $C(n_1)=0.7768$ and $C(n_2)=0.05$. This means that we should stop the trial after stage 1 if the posterior probability of futility exceeds 0.7768, and we should stop the trial after stage 2 if this probability exceeds 0.05. These appear to be fair thresholds on the probability of futility and they will be useful when comparing with other thresholds generated by changing the prior distribution. The algorithm took over one minute to run which is very poor considering the precision of our parameter estimates is $\pm0.025$, $\pm0.025$, $\pm2$, and $\pm2.5$, respectively. We will discuss the efficiency of this method later.

## Evaluation

In the above implementation of the BOP2 clinical trial design we have used $\theta\sim Beta(0.5, 0.5)$ as a prior distribution for $\theta$. Below is the corresponding probability density function.

<center>

```{r echo=FALSE}
x <- seq(0, 1, length = 1000)
y <- dbeta(x, shape1 = 0.5, shape2 = 0.5)
plot(x, y, type = "l", xlab = expression(theta), ylab = "PDF", main = 'Beta(0.5,0.5) distribution', lwd = 2)
```

</center>

We can see that the distribution is symmetric about 0.5, and indeed we have $Pr(\theta<0.5)=Pr(\theta\ge0.5)=0.5$. This gives us no information on whether we think patients will respond to treatment prior to our clinical trial. We will now consider two more informative cases. In Case A, suppose we are more certain that the patients will not respond to treatment. In Case B, suppose we are more certain that the patients will respond to treatment. We can express these prior beliefs in Case A and Case B as the following distributions: $\theta_{A}\sim Beta(a=2,b=5)$ and $\theta_B\sim Beta(a=5,b=2)$. Below are the corresponding probability density functions.

<center>

```{r echo=FALSE}
x <- seq(0, 1, length.out = 1000)
plot(x, dbeta(x, 2, 5), type = "l", col = "blue", lwd = 2, 
     xlab = expression(theta), ylab = "PDF", 
     main = "Beta(2,5) and Beta(5,2) distributions")
lines(x, dbeta(x, 5, 2), type = "l", col = "red", lwd = 2)
legend("topright", lwd = 2, col = c("blue", "red"),
       legend = c("Case A - Beta(2,5)", "Case B - Beta(5,2)"))
```

</center>

The prior probabilities of futility are now $Pr(\theta_A<0.5)=0.8906$ and $Pr(\theta_B<0.5)=0.1094$ for the two cases. Notice that these probabilities sum to 1 as the distributions are mirror images of each other about 0.5. This ensures we have a fair comparison between the two cases. We can now optimise again, but this time using our new prior distributions. Starting with Case A

```{r echo=TRUE}
BOP2optim(a = 2, b = 5) # This will take around 1 minute to run. 
```

The parameters are now $\lambda=0.85$, $\gamma=0.55$, $n_1=12$, and $n_2=50$. The sample size parameters have both increased here however the expected sample size has decreased to 16.557. This is due to the higher probability of the treatment not working, and therefore not proceeding to stage 2. The threshold values are given by $C(n_1)=0.6123$ and $C(n_2)=0.15$. The stage 1 threshold has become slightly harsher whereas the stage 2 threshold has become more lenient. In Case A, we are expecting that patients will not respond to treatment. Therefore, we would require an outstanding response from the patients during stage 2 to reach the previous threshold of 0.05. Satisfying the threshold $C(n_2)=0.15$ is enough to go against the prior beliefs and confidently say that patients have responded to treatment. The type I and II error rates continue to satisfy the constraints as is the nature of the algorithm. For Case B we have

```{r}
BOP2optim(a = 5, b = 2) # This will take around 1 minute to run.
```

Conversely, in Case B, the expected sample size has increased from the original to 48.784. Naturally the expected sample size increases as we are more likely to proceed to stage 2, however the sample size parameters ($n_1=16$, $n_2=60$) have also increased, and are even larger than in Case A. It appears we require more patients to guarantee that the treatment is indeed working and confirm there is no evidence against this. Case B provides stopping rule parameter of $\lambda=0.95$ and $\gamma=0.05$. The corresponding threshold values are $C(n_1)=0.1108$ and $C(n_2)=0.05$. There has been a significant reduction in the threshold value at the end of stage 1. In Case B, we are expecting that the treatment will have an effect on the patients therefore any suggestion by the data against this should be taken seriously. Furthermore, note that $E[\theta_B]=\frac{5}{7}\approx0.714$ however the alternative hypothesis is $\theta_1=0.7$. This is reflected in the extremely low threshold at the end of stage 1. Additionally, note that the stopping parameter $\lambda$ is the same as the uninformative case.

## Discussion

At the beginning of this report we aimed to assess how utilising an informative prior distribution would effect the optimised parameters. We studied three possibilities for our opinions prior to the clinical trial, firstly the uninformative case, and then Cases A and B. In Case A, we believed patients would not respond to treatment, and in Case B we believed they would. Both events caused increases in sample size parameters compared to the uninformative case. The larger increase in sample size parameters in Case B compared to Case A was perhaps an unexpected, although beneficial, result. It was demonstrated that the beliefs in Case A reduced the expected sample size as we did not anticipate proceeding to stage 2, and conversely for Case B. For the stopping rule parameters, $\lambda$ has remained fairly consistent throughout the three cases we have considered. $\lambda=0.95$, and therefore $C(n_2)=0.05$, appears to be a sensible choice in most applications. This means that to proceed to a phase III clinical trial the probability of futility must not exceed 0.05. Conversely, we have observed a significant change in the value of $\gamma$, therefore this should be specific to each trial. Comparing to the thresholds from the uninformative case, Case A produced a lower stage 1 threshold and a higher stage 2 threshold. Case B produced the same stage 2 threshold as the uninformative case but a strict stage 1 threshold. This may have been because $E[\theta_B]\approx0.714$ which is above the alternative hypothesis $\theta_1=0.7$. These results provide an insight into how the information provided by the prior distribution effects the trial design.

In this report we used a grid search to find the optimal parameter values. Evaluating a grid does not guarantee to find the exact global minimum, therefore we have been careful not to make the grid too small and overlook a plausible approximation for the minimum. The BOP2 design does not state any upper bounds on the parameters $\gamma$, $n_1$, or $n_2$. However, to use a grid search method we are forced to constrain these parameters. In our application we have searched over the grid $0\le\lambda\le1$, $0<\gamma\le2$, $4\le n_1\le20$, $5\le n_2\le80$. The precision of our estimates is $\pm0.025$, $\pm0.025$, $\pm2$, and $\pm2.5$, respectively. Furthermore, one optimisation took slightly over one minute to complete. Throughout this report we have optimised the design three times, therefore it could take up to five minutes to execute the code in this report. This is an ineffective and time consuming process, although the output has (eventually) provided useful information. To improve the optimisation process we would need a general purpose optimisation function in R, capable of undertaking constraints on the outputs, and capable of determining the parameters over the positive real numbers or the positive integers.

To summarise, we have successfully applied the BOP2 clinical trial design, and evaluated the effect of changing the prior distribution. However, the efficiency of our method should be improved.

## Appendix

<https://github.com/mm22ajg/Assignment-2-Programming-.git>
